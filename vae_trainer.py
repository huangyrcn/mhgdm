"""
VAEè®­ç»ƒå™¨ - ç®€åŒ–ç‰ˆæœ¬
æ”¯æŒåŒæ›²å›¾è‡ªç¼–ç å™¨è®­ç»ƒï¼Œé›†æˆå…ƒæµ‹è¯•ç›‘æ§
"""

import os
import sys
import time
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import wandb
from tqdm import trange, tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.config_utils import load_config, save_config
from utils.data_utils import MyDataset
from utils.loader import load_seed, load_device, load_batch, load_model
from utils.graph_utils import node_flags
from models.GraphVAE import GraphVAE
from models.Decoders import Classifier
import torch.nn.functional as F


class EarlyStopping:
    """æ—©åœæœºåˆ¶ - ç›‘æ§Meta-Testå‡†ç¡®ç‡"""

    def __init__(self, patience=5, min_delta=0.01, mode="max"):
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.best_score = None
        self.counter = 0
        self.early_stop = False

    def __call__(self, score):
        if self.best_score is None:
            self.best_score = score
            return False

        if self.mode == "max":
            improved = score > self.best_score + self.min_delta
        else:
            improved = score < self.best_score - self.min_delta

        if improved:
            self.best_score = score
            self.counter = 0
            return False
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
                return True
            return False


class VAETrainer:
    """VAEè®­ç»ƒå™¨"""

    def __init__(self, config_path):
        # åŠ è½½é…ç½®
        self.config = load_config(config_path)

        # è®¾ç½®åŸºæœ¬å‚æ•°
        self.seed = load_seed(self.config.seed)
        self.device = load_device(self.config)
        self.run_name = self.config.run_name

        # åˆå§‹åŒ–wandb
        self._init_wandb()

        # åŠ è½½æ•°æ®é›†
        self.dataset = MyDataset(self.config.data, self.config.fsl_task)
        self.train_loader, self.test_loader = self.dataset.get_loaders()

        # åˆå§‹åŒ–æ¨¡å‹
        self._init_model()

        # åˆ›å»ºä¿å­˜ç›®å½•
        self.save_dir = os.path.join(
            self.config.paths.save_dir, self.config.exp_name, self.config.timestamp
        )
        os.makedirs(self.save_dir, exist_ok=True)

        tqdm.write(f"VAE Trainer initialized: {self.run_name}")
        tqdm.write(f"Save directory: {self.save_dir}")
        tqdm.write(f"Device: {self.device}")

        # Meta-testè®¾ç½®
        self.meta_test_enabled = (
            hasattr(self.config, "fsl_task") and self.config.fsl_task is not None
        )
        if self.meta_test_enabled:
            tqdm.write(
                f"âœ“ Meta-test enabled with {self.config.fsl_task.N_way}-way {self.config.fsl_task.K_shot}-shot"
            )
        else:
            tqdm.write("âœ— Meta-test disabled: no fsl_task config")

        # æ—©åœæœºåˆ¶åˆå§‹åŒ–
        self.enable_early_stopping = getattr(self.config.vae.train, "enable_early_stopping", True)

        if self.enable_early_stopping:
            early_stop_patience = getattr(self.config.vae.train, "early_stop_patience", 5)
            early_stop_min_delta = getattr(self.config.vae.train, "early_stop_min_delta", 0.01)
            self.early_stopping = EarlyStopping(
                patience=early_stop_patience,
                min_delta=early_stop_min_delta,
                mode="max",  # Meta-Testå‡†ç¡®ç‡è¶Šé«˜è¶Šå¥½
            )
            tqdm.write(
                f"âœ“ Early stopping enabled: patience={early_stop_patience}, min_delta={early_stop_min_delta}"
            )
        else:
            self.early_stopping = None
            tqdm.write("âœ— Early stopping disabled - full training curve will be recorded")

    def _init_wandb(self):
        """åˆå§‹åŒ–wandb"""
        mode = (
            "disabled"
            if self.config.debug
            else ("online" if self.config.wandb.online else "offline")
        )

        wandb.init(
            project=self.config.wandb.project,
            entity=self.config.wandb.entity,
            name=self.run_name,
            config=self.config.to_dict(),
            mode=mode,
            dir=os.path.join("logs", "wandb"),
        )

    def _init_model(self):
        """åˆå§‹åŒ–VAEæ¨¡å‹"""
        # åˆ›å»ºGraphVAEé…ç½®å¯¹è±¡
        from types import SimpleNamespace

        vae_config = SimpleNamespace()
        vae_config.pred_node_class = self.config.vae.loss.pred_node_class
        vae_config.pred_edge = self.config.vae.loss.pred_edge
        vae_config.pred_graph_class = self.config.vae.loss.pred_graph_class
        vae_config.use_kl_loss = self.config.vae.loss.use_kl_loss
        vae_config.use_base_proto_loss = self.config.vae.loss.use_base_proto_loss
        vae_config.use_sep_proto_loss = self.config.vae.loss.use_sep_proto_loss

        # è®¾ç½®ç¼–ç å™¨å’Œè§£ç å™¨é…ç½®ï¼Œè¡¥å……ç¼ºå¤±çš„å­—æ®µ
        vae_config.encoder_config = self.config.vae.encoder
        vae_config.encoder_config.input_feature_dim = self.config.data.max_feat_num

        vae_config.decoder_config = self.config.vae.decoder
        vae_config.decoder_config.latent_feature_dim = self.config.vae.encoder.latent_feature_dim
        vae_config.decoder_config.output_feature_dim = self.config.data.max_feat_num

        vae_config.latent_dim = self.config.vae.encoder.latent_feature_dim
        vae_config.device = self.device

        # åˆ›å»ºGraphVAE
        self.model = GraphVAE(vae_config).to(self.device)

        # åˆ›å»ºä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=self.config.vae.train.lr,
            weight_decay=self.config.vae.train.weight_decay,
        )

        # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨ - æ”¹è¿›ç‰ˆ
        if self.config.vae.train.lr_schedule:
            # æ”¯æŒå¤šç§è°ƒåº¦ç­–ç•¥
            scheduler_type = getattr(self.config.vae.train, "scheduler_type", "exponential")

            if scheduler_type == "exponential":
                self.scheduler = optim.lr_scheduler.ExponentialLR(
                    self.optimizer, gamma=self.config.vae.train.lr_decay
                )
            elif scheduler_type == "cosine":
                # Cosine Annealingè°ƒåº¦
                self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
                    self.optimizer,
                    T_max=self.config.vae.train.num_epochs,
                    eta_min=self.config.vae.train.lr * 0.01,  # æœ€ä½å­¦ä¹ ç‡ä¸ºåˆå§‹çš„1%
                )
            elif scheduler_type == "step":
                # é˜¶æ¢¯å¼è¡°å‡
                step_size = getattr(self.config.vae.train, "lr_step_size", 100)
                self.scheduler = optim.lr_scheduler.StepLR(
                    self.optimizer, step_size=step_size, gamma=self.config.vae.train.lr_decay
                )
            else:
                # é»˜è®¤ä½¿ç”¨æŒ‡æ•°è¡°å‡
                self.scheduler = optim.lr_scheduler.ExponentialLR(
                    self.optimizer, gamma=self.config.vae.train.lr_decay
                )

            # Warm-upè°ƒåº¦å™¨æ”¯æŒ
            warmup_epochs = getattr(self.config.vae.train, "warmup_epochs", 0)
            if warmup_epochs > 0:
                from torch.optim.lr_scheduler import LambdaLR

                def warmup_lambda(epoch):
                    if epoch < warmup_epochs:
                        return (epoch + 1) / warmup_epochs
                    return 1.0

                self.warmup_scheduler = LambdaLR(self.optimizer, warmup_lambda)
                self.use_warmup = True
                tqdm.write(f"âœ“ Warm-up enabled: {warmup_epochs} epochs")
            else:
                self.use_warmup = False

            tqdm.write(f"âœ“ LR Scheduler: {scheduler_type}, decay: {self.config.vae.train.lr_decay}")
        else:
            self.scheduler = None
            self.use_warmup = False

        # è·å–ç¼–ç å™¨
        self.encoder = self.model.encoder

        tqdm.write(f"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}")

        # åˆå§‹åŒ–å…ƒæµ‹è¯•ç›¸å…³ç»„ä»¶
        self._init_meta_test_components()

    def _init_meta_test_components(self):
        """åˆå§‹åŒ–meta-testè¯„ä¼°ç»„ä»¶ - ç®€åŒ–ç‰ˆæœ¬"""
        if not hasattr(self.config, "fsl_task") or self.config.fsl_task is None:
            print("No FSL task config found. Meta-test evaluation disabled.")
            self.meta_test_enabled = False
            return

        self.meta_test_enabled = True
        fsl_config = self.config.fsl_task

        # ä»é…ç½®è¯»å–å‚æ•°
        N_way = fsl_config.N_way
        meta_test_tasks = getattr(fsl_config, "meta_test_tasks", 10)

        # ç®€å•çº¿æ€§æ¢é’ˆ - ç›´æ¥ä½¿ç”¨å›ºå®šç»´åº¦
        latent_dim = self.config.vae.encoder.latent_feature_dim
        self.linear_probe = torch.nn.Linear(latent_dim, N_way).to(self.device)

        print(f"âœ“ Meta-test components initialized:")
        print(f"  N-way: {N_way}, K-shot: {fsl_config.K_shot}, R-query: {fsl_config.R_query}")
        print(f"  Meta-test tasks: {meta_test_tasks}")
        print(f"  Linear probe: {latent_dim} -> {N_way}")

    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        tqdm.write(f"Starting VAE training: {self.run_name}")

        best_test_loss = float("inf")
        best_meta_test_acc = 0.0

        progress_bar = tqdm(
            range(self.config.vae.train.num_epochs),
            desc="Training",
            ncols=100,
            leave=True,
            ascii=True,
        )

        for epoch in progress_bar:
            # è®­ç»ƒé˜¶æ®µ - æ¯ä¸ªepochåéƒ½æäº¤è®­ç»ƒloss
            train_losses = self._train_epoch()
            mean_train_loss = np.mean(train_losses["total"])

            # æäº¤è®­ç»ƒæŸå¤±åˆ°wandb
            train_log = {
                "epoch": epoch,
                "train_loss": mean_train_loss,
                "train_rec_loss": np.mean(train_losses["rec"]),
                "train_kl_loss": np.mean(train_losses["kl"]),
                "train_edge_loss": np.mean(train_losses["edge"]),
                "lr": self.optimizer.param_groups[0]["lr"],
            }
            wandb.log(train_log)

            # æ›´æ–°å­¦ä¹ ç‡
            if self.scheduler:
                if self.use_warmup and epoch < getattr(self.config.vae.train, "warmup_epochs", 0):
                    # Warm-upé˜¶æ®µ
                    self.warmup_scheduler.step()
                else:
                    # æ­£å¸¸è°ƒåº¦é˜¶æ®µ
                    self.scheduler.step()

            # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›è¡Œæµ‹è¯•
            should_test = (epoch % self.config.vae.train.test_interval == 0) or (
                epoch == self.config.vae.train.num_epochs - 1
            )

            if should_test:
                # æµ‹è¯•é˜¶æ®µ
                test_losses = self._test_epoch()
                mean_test_loss = np.mean(test_losses["total"])

                # å…ƒæµ‹è¯•è¯„ä¼°
                meta_test_acc = 0.0
                if self.meta_test_enabled:
                    meta_test_acc = self._meta_test_evaluation(epoch)

                # æäº¤æµ‹è¯•æŸå¤±å’ŒæŒ‡æ ‡åˆ°wandb
                test_log = {
                    "epoch": epoch,
                    "test_loss": mean_test_loss,
                    "test_rec_loss": np.mean(test_losses["rec"]),
                    "test_kl_loss": np.mean(test_losses["kl"]),
                    "test_edge_loss": np.mean(test_losses["edge"]),
                    "meta_test_accuracy": meta_test_acc,
                }
                wandb.log(test_log)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æœ€ä½³æ¨¡å‹
                is_best_loss = mean_test_loss < best_test_loss
                is_best_meta_acc = meta_test_acc > best_meta_test_acc

                if is_best_loss:
                    best_test_loss = mean_test_loss
                    self._save_checkpoint(epoch, mean_test_loss, meta_test_acc, "best_loss")
                    progress_bar.write(f"âœ“ New best loss: {mean_test_loss:.6f}")

                if is_best_meta_acc:
                    best_meta_test_acc = meta_test_acc
                    self._save_checkpoint(epoch, mean_test_loss, meta_test_acc, "best_meta_acc")
                    progress_bar.write(f"âœ“ New best meta-acc: {meta_test_acc:.4f}")

                # æ—©åœæ£€æŸ¥ - åªåœ¨å¯ç”¨æ—¶æ‰§è¡Œ
                if (
                    self.enable_early_stopping
                    and self.meta_test_enabled
                    and self.early_stopping is not None
                ):
                    should_early_stop = self.early_stopping(meta_test_acc)
                    if should_early_stop:
                        progress_bar.write(f"ğŸ›‘ Early stopping triggered at epoch {epoch}")
                        progress_bar.write(
                            f"   Best Meta-Test Acc: {self.early_stopping.best_score:.4f}"
                        )
                        progress_bar.write(
                            f"   No improvement for {self.early_stopping.patience} consecutive evaluations"
                        )
                        # ä¿å­˜æ—©åœæ—¶çš„æ¨¡å‹
                        self._save_checkpoint(epoch, mean_test_loss, meta_test_acc, "early_stop")
                        break

                # æ›´æ–°è¿›åº¦æ¡
                progress_bar.set_postfix(
                    {
                        "Train": f"{mean_train_loss:.6f}",
                        "Best-Meta": f"{best_meta_test_acc:.4f}",
                    }
                )

                tqdm.write(
                    f"Epoch {epoch}: Train={mean_train_loss:.6f}, Test={mean_test_loss:.6f}, Meta-Test Acc={meta_test_acc:.4f}"
                )
            else:
                # éæµ‹è¯•epoch - åªæ˜¾ç¤ºè®­ç»ƒlosså’Œæœ€ä½³metaå‡†ç¡®ç‡
                progress_bar.set_postfix(
                    {
                        "Train": f"{mean_train_loss:.6f}",
                        "Best-Meta": f"{best_meta_test_acc:.4f}",
                    }
                )

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_test_losses = self._test_epoch()
        final_mean_test_loss = np.mean(final_test_losses["total"])
        final_meta_test_acc = 0.0
        if self.meta_test_enabled:
            final_meta_test_acc = self._meta_test_evaluation(self.config.vae.train.num_epochs - 1)

        self._save_checkpoint(
            self.config.vae.train.num_epochs - 1, final_mean_test_loss, final_meta_test_acc, "final"
        )

        tqdm.write(
            f"Training completed. Best test loss: {best_test_loss:.6f}, Best meta-test acc: {best_meta_test_acc:.4f}"
        )
        return self.save_dir

    def _train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        losses = {"total": [], "rec": [], "kl": [], "edge": []}

        for batch in self.train_loader:
            x, adj, labels = load_batch(batch, self.device)

            self.optimizer.zero_grad()

            # å‰å‘ä¼ æ’­
            (
                rec_loss,
                kl_loss,
                edge_loss,
                base_proto_loss,
                sep_proto_loss,
                graph_classification_loss,
                acc_proto,
            ) = self.model(x, adj, labels)

            # è®¡ç®—æ€»æŸå¤±
            total_loss = (
                self.config.vae.train.rec_weight * rec_loss
                + self.config.vae.train.kl_regularization * kl_loss
                + self.config.vae.train.edge_weight * edge_loss
                + self.config.vae.train.base_proto_weight * base_proto_loss
                + self.config.vae.train.sep_proto_weight * sep_proto_loss
                + self.config.vae.train.graph_classification_weight * graph_classification_loss
            )

            # åå‘ä¼ æ’­
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.vae.train.grad_norm)
            self.optimizer.step()

            # è®°å½•æŸå¤±
            losses["total"].append(total_loss.item())
            losses["rec"].append(rec_loss.item())
            losses["kl"].append(kl_loss.item())
            losses["edge"].append(edge_loss.item())

        return losses

    def _test_epoch(self):
        """æµ‹è¯•ä¸€ä¸ªepoch"""
        self.model.eval()
        losses = {"total": [], "rec": [], "kl": [], "edge": []}

        with torch.no_grad():
            for batch in self.test_loader:
                x, adj, labels = load_batch(batch, self.device)

                # å‰å‘ä¼ æ’­
                (
                    rec_loss,
                    kl_loss,
                    edge_loss,
                    base_proto_loss,
                    sep_proto_loss,
                    graph_classification_loss,
                    acc_proto,
                ) = self.model(x, adj, labels)

                # è®¡ç®—æ€»æŸå¤±
                total_loss = (
                    self.config.vae.train.rec_weight * rec_loss
                    + self.config.vae.train.kl_regularization * kl_loss
                    + self.config.vae.train.edge_weight * edge_loss
                    + self.config.vae.train.base_proto_weight * base_proto_loss
                    + self.config.vae.train.sep_proto_weight * sep_proto_loss
                    + self.config.vae.train.graph_classification_weight * graph_classification_loss
                )

                # è®°å½•æŸå¤±
                losses["total"].append(total_loss.item())
                losses["rec"].append(rec_loss.item())
                losses["kl"].append(kl_loss.item())
                losses["edge"].append(edge_loss.item())

        return losses

    def _meta_test_evaluation(self, epoch):
        """Meta-test evaluation using linear probing"""
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„FSLå‚æ•°
        N_way = self.config.fsl_task.N_way
        K_shot = self.config.fsl_task.K_shot
        R_query = self.config.fsl_task.R_query
        meta_test_tasks = getattr(self.config.fsl_task, "meta_test_tasks", 10)

        self.encoder.eval()
        all_task_accuracies = []

        try:
            for task_idx in range(meta_test_tasks):
                task = self.dataset.sample_one_task(
                    is_train=False,
                    N_way=N_way,
                    K_shot=K_shot,
                    R_query=R_query,
                    query_pool_start_index=task_idx * R_query,
                )

                if task is None:
                    continue

                # å°†ä»»åŠ¡æ•°æ®ç§»åˆ°è®¾å¤‡
                support_x = task["support_set"]["x"].to(self.device)
                support_adj = task["support_set"]["adj"].to(self.device)
                support_labels = task["support_set"]["label"].to(self.device)
                query_x = task["query_set"]["x"].to(self.device)
                query_adj = task["query_set"]["adj"].to(self.device)
                query_labels = task["query_set"]["label"].to(self.device)

                # æå–ç‰¹å¾
                support_features = self._extract_features(support_x, support_adj)
                query_features = self._extract_features(query_x, query_adj)

                # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºæ–°çš„çº¿æ€§æ¢é’ˆ
                actual_N_way = task.get("N_way", N_way)
                latent_dim = self.config.vae.encoder.latent_feature_dim
                task_linear_probe = torch.nn.Linear(latent_dim, actual_N_way).to(self.device)

                # è®­ç»ƒå¹¶æµ‹è¯•çº¿æ€§æ¢é’ˆ
                accuracy = self._train_and_test_probe(
                    support_features,
                    support_labels,
                    query_features,
                    query_labels,
                    task_linear_probe,
                )
                all_task_accuracies.append(accuracy)

        except Exception as e:
            tqdm.write(f"Error in meta-test evaluation: {e}")
            return 0.0

        # è®¡ç®—æœ€ç»ˆç»“æœ
        if all_task_accuracies:
            mean_accuracy = np.mean(all_task_accuracies)
            return mean_accuracy
        else:
            return 0.0

    def _extract_features(self, x_batch, adj_batch):
        """ä½¿ç”¨ç¼–ç å™¨æå–ç‰¹å¾"""
        with torch.no_grad():
            # ç”Ÿæˆnode_mask
            from utils.graph_utils import node_flags

            node_mask = node_flags(adj_batch)
            node_mask = node_mask.unsqueeze(-1)  # å¢åŠ æœ€åä¸€ä¸ªç»´åº¦

            # ä½¿ç”¨ç¼–ç å™¨æå–ç‰¹å¾
            posterior = self.encoder(x_batch, adj_batch, node_mask)
            z_mu = posterior.mode()  # è·å–åéªŒåˆ†å¸ƒçš„æ¨¡å¼

            # å¯¹äºå›¾çº§åˆ«çš„åˆ†ç±»ï¼Œæˆ‘ä»¬éœ€è¦èšåˆèŠ‚ç‚¹ç‰¹å¾
            # ä½¿ç”¨å¹³å‡æ± åŒ–ï¼ŒåŒæ—¶è€ƒè™‘node_mask
            node_mask_for_pooling = node_mask.squeeze(-1)  # [batch_size, num_nodes]
            masked_features = z_mu * node_mask.expand_as(z_mu)  # åº”ç”¨mask

            # è®¡ç®—æ¯ä¸ªå›¾çš„æœ‰æ•ˆèŠ‚ç‚¹æ•°
            num_valid_nodes = node_mask_for_pooling.sum(dim=1, keepdim=True)  # [batch_size, 1]
            num_valid_nodes = torch.clamp(num_valid_nodes, min=1.0)  # é¿å…é™¤é›¶

            # å¹³å‡æ± åŒ–å¾—åˆ°å›¾çº§ç‰¹å¾
            graph_features = (
                masked_features.sum(dim=1) / num_valid_nodes
            )  # [batch_size, latent_dim]

            return graph_features

    def _train_and_test_probe(
        self, support_features, support_labels, query_features, query_labels, task_linear_probe
    ):
        """è®­ç»ƒçº¿æ€§æ¢é’ˆå¹¶æµ‹è¯• - ç®€åŒ–ç‰ˆæœ¬"""
        # é‡ç½®çº¿æ€§æ¢é’ˆå‚æ•°
        torch.nn.init.xavier_uniform_(task_linear_probe.weight)
        torch.nn.init.zeros_(task_linear_probe.bias)

        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(task_linear_probe.parameters(), lr=0.01)
        criterion = torch.nn.CrossEntropyLoss()

        # æ—©åœå‚æ•°
        best_loss = float("inf")
        patience = 10
        patience_counter = 0
        max_epochs = 100

        # è®­ç»ƒçº¿æ€§æ¢é’ˆ
        task_linear_probe.train()
        for epoch in range(max_epochs):
            optimizer.zero_grad()

            # å‰å‘ä¼ æ’­
            logits = task_linear_probe(support_features)
            loss = criterion(logits, support_labels)

            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()

            # æ—©åœæ£€æŸ¥
            if loss.item() < best_loss:
                best_loss = loss.item()
                patience_counter = 0
            else:
                patience_counter += 1

            if patience_counter >= patience:
                break

        # æµ‹è¯•
        task_linear_probe.eval()
        with torch.no_grad():
            query_logits = task_linear_probe(query_features)
            predictions = torch.argmax(query_logits, dim=1)
            correct = (predictions == query_labels).float().sum().item()
            accuracy = correct / len(query_labels)

        return accuracy

    def _save_checkpoint(self, epoch, test_loss, meta_test_acc, checkpoint_type):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            "epoch": epoch,
            "model_config": self.config.to_dict(),
            "model_state_dict": self.model.state_dict(),
            "optimizer_state_dict": self.optimizer.state_dict(),
            "test_loss": test_loss,
            "meta_test_acc": meta_test_acc,
        }

        if self.scheduler:
            checkpoint["scheduler_state_dict"] = self.scheduler.state_dict()

        # ä¿å­˜æŒ‡å®šç±»å‹çš„æ£€æŸ¥ç‚¹
        checkpoint_path = os.path.join(self.save_dir, f"{checkpoint_type}.pth")
        torch.save(checkpoint, checkpoint_path)


def main():
    parser = argparse.ArgumentParser(description="VAE Trainer")
    parser.add_argument("--config", type=str, required=True, help="é…ç½®æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = VAETrainer(args.config)
    save_dir = trainer.train()

    tqdm.write(f"VAE training completed. Models saved to: {save_dir}")


if __name__ == "__main__":
    main()
