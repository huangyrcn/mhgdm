# MHGDM Project Navigation Guide

## Data Loading System

### Optimized Data Utilities
- **Primary data loader**: [utils/data_utils_optimized.py](mdc:utils/data_utils_optimized.py) - High-performance data loading with 2-3x speedup
- **Graph utilities**: [utils/graph_utils.py](mdc:utils/graph_utils.py) - Core graph manipulation functions
- **Legacy loader**: [utils/data_utils.py](mdc:utils/data_utils.py) - Original data loading implementation

### Dataset Configurations
Dataset configs are in `configs/data/` directory:
- [configs/data/ENZYMES.yaml](mdc:configs/data/ENZYMES.yaml) - 600 graphs, batch_size: 256
- [configs/data/Letter_high.yaml](mdc:configs/data/Letter_high.yaml) - ~2K graphs, batch_size: 128  
- [configs/data/Reddit.yaml](mdc:configs/data/Reddit.yaml) - 1.1K graphs, large graphs (3782 nodes max)
- [configs/data/TRIANGLES.yaml](mdc:configs/data/TRIANGLES.yaml) - 2K graphs, batch_size: 128

## Key Architecture Components

## Three-Stage Training Architecture

### ðŸŽ¯ Training Modules
1. **Stage 1 - Hyperbolic VAE Pretraining**: [vae_trainer.py](mdc:vae_trainer.py) 
   - Trains hyperbolic graph autoencoder
   - Supports PoincareBall, Lorentz manifolds
   - Entry: `python vae_trainer.py training_mode=ae`

2. **Stage 2 - Score Model Training**: [score_trainer.py](mdc:score_trainer.py)
   - Trains generative score networks (X + Adj)
   - Uses pretrained VAE encoder
   - Entry: `python score_trainer.py ae_path=<vae_checkpoint>`

3. **Stage 3 - Meta-Learning**: [meta_test.py](mdc:meta_test.py)
   - Data augmentation + classifier head fine-tuning
   - Few-shot learning evaluation
   - Entry: `python meta_test.py vae_ckpt_path=<vae> score_ckpt_path=<score>`

### ðŸ”§ Experiment Management
- **Unified Manager**: [experiment_manager.py](mdc:experiment_manager.py) - Orchestrates all three stages
- **Experiment Configs**: [configs/experiments/](mdc:configs/experiments/) - Complete experiment configurations  
- **Usage**: `python experiment_manager.py --config configs/experiments/enzymes_three_stage.yaml`

### Training Pipeline
- **Legacy trainer**: [trainer.py](mdc:trainer.py) - Original training entry point

### Models
Core models are in `models/` directory:
- Score networks for adjacency matrices and node features
- Graph VAE implementations
- All models integrate with [utils/graph_utils.py](mdc:utils/graph_utils.py)

## Data Loading Best Practices

### Using Optimized Data Loader
```python
from utils.data_utils_optimized import MyDatasetOptimized

# Enable optimizations in config
data_config.enable_optimization = True
data_config.lazy_tensor_conversion = False  # or True for memory efficiency

# Create dataset with FSL support
dataset = MyDatasetOptimized(data_config, fsl_task_config)
```

### Configuration Requirements
All dataset configs must include:
- `name`: Dataset name matching directory in `datasets/`
- `max_node_num`: Maximum nodes across all graphs
- `max_feat_num`: Feature dimension
- `batch_size`: Training batch size

### Performance Considerations
- **Small datasets** (ENZYMES, TRIANGLES): ~0.2-0.3s load time
- **Medium datasets** (Letter_high): ~0.2s load time  
- **Large datasets** (Reddit): ~90s load time due to 3782 max nodes
- Optimized loader provides 2-3x speedup over legacy version

## File Dependencies
- Data loaders depend on [utils/graph_utils.py](mdc:utils/graph_utils.py) for `graphs_to_tensor`
- All trainers import graph utilities for masking and node operations
- Dataset files must be in `datasets/{name}/{name}.txt` format
- Train/test splits defined in `datasets/{name}/train_test_classes.json`

## Testing Data Loading
To test new datasets or configurations:
1. Ensure dataset files exist in proper structure
2. Create config YAML with correct parameters
3. Test with `MyDatasetOptimized` class
4. Verify FSL task sampling works for few-shot learning scenarios

## Configuration Directories Structure
- `configs/data/`: Dataset configurations
- `configs/model/`: Model architecture configs  
- `configs/train/`: Training hyperparameters
- `configs/fsl_task/`: Few-shot learning task definitions
